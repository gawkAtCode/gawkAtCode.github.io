<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="文本预处理"><meta name="keywords" content="Entity Resolution,NLP"><meta name="author" content="gawkAtCode"><meta name="copyright" content="gawkAtCode"><title>文本预处理 | gawkAtCode's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '5.4.1'
} </script><meta name="generator" content="Hexo 5.4.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">文本预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.1.</span> <span class="toc-text">主要步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E7%9A%84"><span class="toc-number">1.2.</span> <span class="toc-text">目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A41%EF%BC%9Aunitization-and-tokenization-%E7%BB%9F%E4%B8%80%E5%8C%96%E5%92%8C%E5%88%86%E8%AF%8D"><span class="toc-number">1.3.</span> <span class="toc-text">步骤1：unitization and tokenization(统一化和分词)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A42%EF%BC%9Astandardization-and-cleansing-or-text-data-cleansing-%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E6%B8%85%E7%90%86%E6%88%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86"><span class="toc-number">1.4.</span> <span class="toc-text">步骤2：standardization and cleansing or text data cleansing(标准化和清理或文本数据清理)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A43%EF%BC%9Astop-word-removal-%E5%88%A0%E9%99%A4%E5%81%9C%E7%94%A8%E8%AF%8D"><span class="toc-number">1.5.</span> <span class="toc-text">步骤3：stop word removal(删除停用词)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A44%EF%BC%9Astemming-or-lemmatization-%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96%E6%88%96%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F"><span class="toc-number">1.6.</span> <span class="toc-text">步骤4：stemming or lemmatization(词干提取或词形还原)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">2.</span> <span class="toc-text">参考文献</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">gawkAtCode</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">gawkAtCode's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="post-info"><div id="post-title">文本预处理</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-03-21</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h2><p>&emsp;&emsp;在进行文本分析之前，应当对文本进行相应地预处理。许多文本预处理方法都来源于NLP(自然语言处理)。</p>
<h3 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h3><p>&emsp;&emsp;《PracticalText Analytics》[1]把文本预处理过程分为以下几个步骤：<br>&emsp;&emsp;(1)unitization and tokenization                                统一化和分词<br>&emsp;&emsp;(2)standardization and cleansing or text data cleansing        标准化和清理或文本数据清理<br>&emsp;&emsp;(3)stop word removal                                           删除停用词<br>&emsp;&emsp;(4)stemming or lemmatization                                   词干提取或词形还原</p>
<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>&emsp;&emsp;(1)将数据进行标准化，从而减少数据的维度</p>
<h3 id="步骤1：unitization-and-tokenization-统一化和分词"><a href="#步骤1：unitization-and-tokenization-统一化和分词" class="headerlink" title="步骤1：unitization and tokenization(统一化和分词)"></a>步骤1：unitization and tokenization(统一化和分词)</h3><p>&emsp;&emsp;首先是根据文本分析方法选择文本的最小单位，这个单位可以是一个词，可以是一个句子，甚至一个段落、一个文档。<br>&emsp;&emsp;(1)<strong>Word</strong> tokenizer<br>&emsp;&emsp;&emsp;&emsp;最简单的一种分词方法，把句子分成一个个单词。<br>&emsp;&emsp;(2)<strong>Q-grams</strong> tokenizer[2,3]<br>&emsp;&emsp;&emsp;&emsp;先用其他的tokenizer得到token，再从token中提取一系列q-grams(长度为q的滑动窗口)<br>&emsp;&emsp;&emsp;&emsp;<strong>举例</strong>：q=2 token=”Pet-Can”<br>&emsp;&emsp;&emsp;&emsp;<strong>q-grams</strong>：”(1,*P)”, “(2,Pe)”, “(3,et)”, “(4, t-)”, “(5, -C)”, “(6, Ca)”, “(7, an)”<br>&emsp;&emsp;(3)<strong>Suffix Arrays</strong> tokenizer[4]<br>&emsp;&emsp;&emsp;&emsp;先用其他的tokenizer得到token，再从token中提取一系列Suffix Arrays(长度为l的后缀)<br>&emsp;&emsp;&emsp;&emsp;<strong>举例</strong>：l=4 token=”Kristen”<br>&emsp;&emsp;&emsp;&emsp;<strong>Suffix Arrays</strong>：”Kristen”, “risten”, “isten”, “sten”<br>&emsp;&emsp;(4)<strong>Model Word</strong> tokenizer[5]<br>&emsp;&emsp;&emsp;&emsp;模型词的定义为:至少有一个数字字符和至少一个非数字字符的单词<br>&emsp;&emsp;&emsp;&emsp;<strong>举例</strong>：Philips 4000 Series, 29” Class LED 720p 60Hz HDTV 29PFL4508F7<br>&emsp;&emsp;&emsp;&emsp;<strong>Model Word</strong>：29”, 720p, 60Hz, 29PFL4508F7<br>&emsp;&emsp;(4)<strong>Byte Pair Encoding</strong> tokenizer[6]<br>&emsp;&emsp;&emsp;&emsp;NLP领域传统的分词方法使用空格分词得到固定的词汇,但会导致罕见词无法处理即OOV(Out of Vocabulary)问题。基于Character embedding的方法粒度太细，而Subword介于字符和词之间，能够较好的处理OOV问题。<br>&emsp;&emsp;&emsp;&emsp;<strong>原理</strong>：将一个token分成多个subtokens<br>&emsp;&emsp;&emsp;&emsp;<strong>举例</strong>：[‘loved’, ‘loving’, ‘loves’]<br>&emsp;&emsp;&emsp;&emsp;<strong>BPE</strong>：[“lov”,”ed”,”ing”,”es”]</p>
<h3 id="步骤2：standardization-and-cleansing-or-text-data-cleansing-标准化和清理或文本数据清理"><a href="#步骤2：standardization-and-cleansing-or-text-data-cleansing-标准化和清理或文本数据清理" class="headerlink" title="步骤2：standardization and cleansing or text data cleansing(标准化和清理或文本数据清理)"></a>步骤2：standardization and cleansing or text data cleansing(标准化和清理或文本数据清理)</h3><h3 id="步骤3：stop-word-removal-删除停用词"><a href="#步骤3：stop-word-removal-删除停用词" class="headerlink" title="步骤3：stop word removal(删除停用词)"></a>步骤3：stop word removal(删除停用词)</h3><h3 id="步骤4：stemming-or-lemmatization-词干提取或词形还原"><a href="#步骤4：stemming-or-lemmatization-词干提取或词形还原" class="headerlink" title="步骤4：stemming or lemmatization(词干提取或词形还原)"></a>步骤4：stemming or lemmatization(词干提取或词形还原)</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007/978-3-319-95663-3.pdf">Anandarajan M, Hill C, Nolan T. Practical text analytics[J]. Maximizing the Value of Text Data.(Advances in Analytics and Data Science. Vol. 2.) Springer, 2019: 45-59.</a></li>
<li>[2] <a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.4563&rep=rep1&type=pdf">R. Baxter, P. Christen, T. Churches, A comparison of fast blocking methods for record linkage, in: Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 3, ACM, 2003, pp. 25–27.</a></li>
<li>[3] <a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.3727">L. Gravano, P.G. Ipeirotis, H.V. Jagadish, N. Koudas, S. Muthukrishnan, D. Srivastava, et al., Approximate String Joins in a Database (Almost) for Free, in: Proceedings of the 27th International Conference on Very Large Data Bases, 1, 2001, pp. 491–500.</a></li>
<li>[4] <a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=24ED124007F1ECB8E79BB62297855291?doi=10.1.1.409.5820&rep=rep1&type=pdf">T. De Vries, H. Ke, S. Chawla, P. Christen, Robust record linkage blocking using suffix arrays, in: Proceedings of the 18th ACM Conference on Information and Knowledge Management, ACM, 2009, pp. 305–314.</a></li>
<li>[4] <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S1566253518304755">Vandic D, Frasincar F, Kaymak U, et al. Scalable entity resolution for Web product descriptions[J]. Information Fusion, 2020, 53: 103-111.</a></li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">gawkAtCode</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/03/21/技术/20220321-文本预处理/">http://example.com/2022/03/21/技术/20220321-文本预处理/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com">gawkAtCode's blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Entity-Resolution/">Entity Resolution</a><a class="post-meta__tags" href="/tags/NLP/">NLP</a></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-6236917046f44389" async></script><nav id="pagination"><div class="next-post pull-right"><a href="/2022/03/21/%E7%AB%9E%E8%B5%9B/ACM%20SIGMOD%20Programming%20Contest/20220321-ACM%20SIGMOD%202022%20Programming%20Contest/"><span>ACM SIGMOD 2022 Programming Contest</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2022 By gawkAtCode</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>